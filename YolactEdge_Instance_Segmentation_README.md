# Github Source Link: https://github.com/haotian-liu/yolact_edge

# Github Fork: https://github.com/adkap2/Instance-Segmentation-with-Unity-Interactive-Augmented-Reality

# Introduction

Computer vision is a rapidly advancing field that involves the development of algorithms and techniques to enable machines to interpret and analyze digital images and videos. It has become increasingly important in recent years due to the explosive growth of visual data generated by various sources such as surveillance cameras, autonomous vehicles, and mobile devices. One of the key areas of application for computer vision is in real-time instance segmentation and object detection, which is used for a wide range of tasks, including robotics, autonomous navigation, object recognition, and image analysis. Real-time instance segmentation and object detection techniques allow machines to identify and locate specific objects within images or video streams in real-time, enabling them to react quickly and accurately to changing conditions. This is particularly important in fields such as medicine, manufacturing, and security, where the ability to detect and respond to potential threats or anomalies in real-time can be critical to ensuring safety and efficiency.

YOLACT Edge is a real-time instance segmentation model designed for edge devices with limited computational resources. Developed by researchers at the University of Michigan, YOLACT Edge is based on the popular YOLACT (You Only Look At CoefficienTs) model, which uses a one-stage object detection and segmentation approach to achieve state-of-the-art performance. YOLACT Edge achieves high accuracy while requiring only a fraction of the computational resources of other real-time instance segmentation models. This makes it ideal for deployment on edge devices such as smartphones, drones, and IoT devices.

One of the key features of YOLACT Edge is its ability to perform instance segmentation and object detection in real-time, making it suitable for a wide range of applications where speed and accuracy are critical. For example, it can be used in autonomous vehicles for pedestrian detection and tracking, in retail environments for real-time inventory management, and in healthcare for medical image analysis. YOLACT Edge can also be used for video analytics in surveillance systems, enabling rapid and accurate detection of potential security threats. Overall, YOLACT Edge is a powerful tool for edge-based computer vision applications, enabling high-performance real-time instance segmentation and object detection in resource-constrained environments.

The objective of this case study is to train a YolactEdge model for real-time instance segmentation inference within the Unity virtualhome environment. To enable real-time inference, the high-performance deep learning inference library TensorRT was utilized. Additionally, communication between UnityVirtualHome and the YolactEdge inference model was established using the NetMQ library through TCP/IP socket communication.

To train the yolact model on indoor environments such as doors, windows, doorways, and countertops, synthetic data was generated using Unity SyntheticHomes. The annotations for each object in the scene were automatically generated with high accuracy using this tool. A total of 637 images were generated using the Unity toolkit, which were then utilized to train and evaluate the model. Following the training and testing of the Yolact Edge model, the model's performance was evaluated in real-time by testing it on the Unity VirtualHome platform.

The incorporation of NetMQ enabled the establishment of a dependable and swift communication link between Unity and YolactEdge. Each frame produced in Unity is compressed and dispatched to YolactEdge for prediction with minimal latency. This entire process operates at approximately 10-15 fps on my system, making it well-suited for various real-time applications.

The forthcoming sections will delve into the specifics of the yolact edge training process, commencing with the installation of the required dependencies and cloning of the yolactedge model. Subsequently, the input frames will be preprocessed and the model will be configured. Ultimately, a performance assessment of the pipeline will be furnished, including an evaluation of the prediction accuracy and system latency.




# Installation

Note: Our computer specifications and installation dependencies are as follows

Operating System
MacOS Monterey 12.6
Chip: Apple M1
Memory: 8 GB 
Accessing HPC: Refer HPC Readme






1. Go to yolact_edge directory: cd yolact_edge

Note: If dependencies in environment.yml break, try installing each dependency manually based on your personal environment.

2. For pretrained Resnet101 weights, download resnet101_reducedfc.pth from https://drive.google.com/file/d/1tvqFPd4bJtakOlmn-uIA492g2qurRChj/view?usp=sharing
3. Make new directory ‘weights’: mkdir weights
4. Place weight file inside weights directory

# Configuring the Model

To prepare YolactEdge for training with a custom dataset, modifications are necessary to the ‘config.py’ file and ‘yolact.py’.  YolactEdge must be properly configured to train on the custom object classes associated with the indoor environment. 

1. Modify the config.py file
Note: config.py is located inside the ‘data’ directory from within the yolact repository
tree
├── backbone.py
├── CHANGELOG.md
├── data
│   ├── coco.py
│   ├── config.py
│   ├── grid.npy
	a. Open ‘config.py’: code config.py
	b. Create a new dataset derived from dataset base and name it SyntheticHome
	Note: DATASETS begin on line 106 in the config.py file

	SyntheticHome = dataset_base.copy({
    		'name': 'SyntheticHome'
	})


	c. Within SyntheticHome, add the file path to the train and validation images and labels
	SyntheticHome = dataset_base.copy({
		'name': 'SyntheticHome',
		'train_images': '/path/to/training/images/',
		'train_info':   '/path/to/training/labels/',
		'valid_images': '/path/to/validation/images/',
		'valid_info':   '/path/to/validation/labels',
	})
	
	d. Within SyntheticHome, add a label map offsetting the index from 0 to 1 with length equal to the number of class labels

	SyntheticHome = dataset_base.copy({
	   'name': 'SyntheticHome',
	   'train_images': 'train_images': '/path/to/training/images/',
	   'train_info':   '/path/to/training/labels/',
	   'valid_images': '/path/to/validation/images/',
	   'valid_info':   '/path/to/validation/labels',
	   'label_map': {0:1, 1:2, 2:3, 3:4, 4:5, 5:6, 6:7},
	})


	e. Within SyntheticHome, add alphabetically ordered ‘class_names’  derived from the annotation file
	SyntheticHome = dataset_base.copy({
	   'name': 'SyntheticHome',
	   'train_images': 'train_images': '/path/to/training/images/',
	   'train_info':   '/path/to/training/labels/',
	   'valid_images': '/path/to/validation/images/',
	   'valid_info':   '/path/to/validation/labels',
	   'label_map': {0:1, 1:2, 2:3, 3:4, 4:5, 5:6, 6:7},
	'class_names': ("Bed", "Bench", "Chair", "Microwave", "Refrigerator", "Sofa", "Table")   
	})


	f. Under YOLACT v1.0 CONFIGS and after yolact_base_config, create a new configuration object named ‘synthetic_home_config’
	 synthetic_home_config = yolact_base_config.copy({ 
	   'name': 'synthetic_home',
	})


	g. Under synthetic_home_config specify the SyntheticHome dataset and class length
	synthetic_home_config = yolact_base_config.copy({
	   'name': 'synthetic_home',
	   # Dataset stuff
	   'dataset': SyntheticHome,
	   # Class length is + 1 to contain background class
	   'num_classes': len(SyntheticHome.class_names) + 1,
	})


	h. Under synthetic_home_config, decrease the learning rate for optimal performance on custom dataset
	synthetic_home_config = yolact_base_config.copy({
	   'name': 'synthetic_home',
	   # Dataset stuff
	   'dataset': SyntheticHome,
	   # Class length is + 1 to contain background class
	   'num_classes': len(SyntheticHome.class_names) + 1,
	   # Slow the learning rate
	   'lr': 1e-4,
	})


	i. Decrease the max number of iterations to 40,000 due to training on custom dataset
	   'max_iter': 40000, # Smaller dataset


	j. Modify the ‘cfg’ variable to read the ‘synthetic_home_config’ object
	Note ‘cfg’ should be located around line 1000
	cfg = synthetic_home_config.copy()


2. Modify the yolact.py file
Note yolact.py is located within the base yolact_edge directory
If performing transfer learning from the pretrained YolactBase model, freeze all trained layers except for the prediction layer.
tree
├── [ 17K]  backbone.py
├── [2.9K]  CHANGELOG.md
├── [4.0K]  data
├── [ 928]  environment.yml
├── [ 46K]  eval.py
├── [4.0K]  external
├── [4.0K]  layers
├── [1.0K]  LICENSE
├── [4.0K]  logs
├── [4.0K]  __pycache__
├── [ 16K]  README.md
├── [4.0K]  results
├── [1.4K]  run_coco_eval.py
├── [4.0K]  scripts
├── [ 21K]  train.py
├── [4.0K]  utils
├── [4.0K]  web
├── [4.0K]  weights
└── [ 31K]  yolact.py



	a. Place the state_dict loader in a try-except block
	Note: this is located around line 1260
	       try:
		   self.load_state_dict(state_dict)
	       except RuntimeError as e:
		   print('Ignoring " ' + str(e)+ '"')



# Training the Model

There are two approaches to training the YolactEdge model on the Unity Synthetic Home generated dataset. 
1. Training the model from scratch
2. Applying transfer learning from a Yolact pretrained model

In our scenario, we opted to train the model from scratch using only the SyntheticHome Generated dataset,  as we anticipated it could lead to superior overall evaluation results. This training process took 6 hours when trained on HPC.

1. From the base yolactedge directory, call ‘train.py’ with the following parameters
Note: the --resume parameter specifies the weights file to begin training from if using transfer learning
Note: --batch_size=5 modifies the number of epochs required for training, the default batch size of 8 requires more Vram usage.

python train.py --config=synthetic_home_config --resume=weights/yolact_base_54_800000.pth --start_iter=0 --batch_size=5


2. Continue training the model until completion

# Evaluation and Inference with YolactEdge


Evaluate the yolact model trained on the custom indoor home dataset
a. cd into the weights file directory: cd weights

b. Locate the most recently trained weights file: ls -l

c. Copy the filename: synthetic_home_851_40000.pth

d. From yolact_edge base dir, call eval.py to evaluate the model with the specified weights file
python eval.py --config=synthetic_home_config --trained_model=weights/synthetic_home_851_40000.pth --score_threshold=0.15 --top_k=15

Citations
[1]
D. Bolya, C. Zhou, F. Xiao, and Y. J. Lee, “YOLACT: Real-Time Instance Segmentation,” in 2019 IEEE/CVF International Conference on Computer Vision (ICCV), 2019.
[2]
H. Liu, R. A. R. Soto, F. Xiao, and Y. J. Lee, “YolactEdge: Real-time instance segmentation on the edge,” arXiv [cs.CV], 2020.
[3]
“VirtualHome,” Virtual-home.org. [Online]. Available: http://virtual-home.org/. [Accessed: 21-Mar-2023].






